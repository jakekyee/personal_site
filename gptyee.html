<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>GPT2WordSalad</title>
  <link rel="stylesheet" href="csstest.css" />
  <link rel="stylesheet" href="passcss.css" />
  <style>
    input[type="text"] {
      font-family: monospace;
      position: relative;
      font-size: 20px;
      width: 80%;
      height: auto;
      text-align: left;
      left: 10%;
      color: var(--fontcolor);
      background-color: var(--bgcolor);
      padding: 1em;
    }

    @media only screen and (max-width: 700px) {
      input[type="text"] {
        left: 0%;
        width: 100%;
      }
    }
  </style>
</head>
<body>
  <div class="middlebit">
    <div class="dotline"></div>
    <h1>GPT2WordSalad</h1>
    <h3>A finetuned GPT-2 model trained on my old writing</h3>
    <hr />

    <br />
    <p>A quick gpt-2 model finetuned on my movie reviews and scholarship essays. Produces gibberish-ish with less than 100 runs and is kinda overfit past it. Garbage in, Garbage out. And I can't really say that the quality of my normal writing is anything but garbage and I didn't really clean up the data at all - so the combination of bad writing and bad techniques just doesn't really work too well. Still produces pretty interesting content though.</p>
    <br />
    <a class="links" href="https://drive.google.com/drive/folders/1k22oIAjGx8pK_FWAt9uLdOMRtwPSwf-d?usp=sharing" style="width:100%; text-align: right; display:inline-block;">Download the Model >></a>
    <hr />
    <div class="dotline"></div>
  </div>

  <div class="middlebit">
    <div class="dotline"></div>
    <h1>Sample Excerpts</h1>
    <h3>Selected outputs from different checkpoints</h3>
    <hr />
    <span>
      <p>From ~50 epochs</p>
      <pre>
A nice write up after the 
decentralized scope of the Narnoo genealogical network was released 
a few months later. 
http://en.wikipedia.org/wiki/Narnoo_(geniere)
The most entertaining part of the book was the briefer, 
emulteated clip series on the microbe count and the more general epiphysemiases in the context of the 
microbial musical chairs musical chairs. 
I remember reading it when I first read it at the time thinking that it was the 
longest read writing that way because it made me feel like I was paying more attention than 
I actually had to. The epigraphs that form the basis of all of the music both live 
and sing in interesting ways. The drone sounds that I remember hearing when I first read the book 
and the repetitive squealing that I then repeated several more times after I finished reading the book was an 
common musical style that I went into all but unimpressed by the final chapter.
      </pre>

      <p>From ~200+ epochs</p>
      <pre>
Gyllenge and the like. The problem is that the solution to the problem is often explicitly stated in the chapter names and the names of places are often hidden in plain sight, making the whole experience less than impressive.

At the same time, the things that make a difference is usually the main focus of the story, and the thing that matters in the Metaverse the most is called 
Meta Knight Biography. The Metaverse was the target of the Bane cyborgs' plan, and the organization quickly lost track of the Infinitesif. The plan went horribly, horribly wrong, and millions of people were killed in the process. Millions of people are at risk of being eaten by Geist if the plan goes awry, and the Metaverse needs your help sending there bounty hunters to find them. The plan also raises some serious ethical and moral questions, namely, do not let evil minions rule over good people, and what is the proper relationship between morality and malicious attacks on one's health or property?

...I reviewed the book on a high-protein, low-carb, and ketogenic schedule, and it looked pretty OK. The list of uses for the Metaverse goes on and on, with more and more people using it as a data centre or data center for analytics and testing, and as data mines for weapons of mass destruction. The Metaverse itself seems to be enjoying a renaissance, having surpassed the pet store industry in popularity and has recently become a hotspot for new talent.
      </pre>
    </span>
    <hr />
    <div class="dotline"></div>
  </div>

  <div class="middlebit">
    <div class="dotline"></div>
    <h1>FAQ</h1>
    <h3>Questions That Are Frequently Asked</h3>
    <hr />
    <span>
      <p>Q: Why did you train this?</p>
      <p>A: I was really interested in LLMs in early 2022, and I saw that other people had some pretty successful results in training them. Mine was not so successful, but it was a good learning experience.</p>
      <br>
      <br>
      <p>Q: Why is it so garbage compared to ChatGPT?</p>
      <p>A: I did this project before ChatGPT even existed. Also I'm not exactly the best writer, so the training data wasn't all that good in the first place. Garbage in, garbage out, as they say.</p>
      <br>
      <br>


      <p>Q: Can I run it myself?</p>
      <p>A: Sure. Download the model from <a href="https://drive.google.com/drive/folders/1k22oIAjGx8pK_FWAt9uLdOMRtwPSwf-d?usp=sharing">here</a> and load it with any basic GPT-2 script.</p>
    </span>
    <hr />
    <div class="dotline"></div>
  </div>

  <footer>
    <p></p>
  </footer>

  <script src="jstest.js"></script>
</body>
</html>
